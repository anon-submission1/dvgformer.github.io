<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Planning 3D camera trajectory for recording drone videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DVGFormer</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* For the 3D container:
       We'll make sure Three.js fills it entirely. */
    .viewer>canvas {
      width: 100% !important;
      height: 100% !important;
    }
  </style>
</head>

<body>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/PLYLoader.js"></script>

  <script>
    // -----------------------------
    // The reusable viewer function
    // -----------------------------
    function create3DViewer(containerId, pointcloudPath, meshPath, cameraLocation, rendererTarget, fov = 20) {
      // 1. Get container reference
      const container = document.getElementById(containerId);
      if (!container) {
        console.error(`Container with ID '${containerId}' not found.`);
        return;
      }

      // 2. Create scene
      const scene = new THREE.Scene();
      scene.background = new THREE.Color(0xffffff);

      // 3. Create camera
      const camera = new THREE.PerspectiveCamera(
        fov,
        container.clientWidth / container.clientHeight,
        0.1,
        1000
      );
      camera.position.set(...cameraLocation);
      camera.up.set(0, 0, 1);

      // 4. Create renderer and add to container
      const renderer = new THREE.WebGLRenderer({ antialias: true });
      renderer.setSize(container.clientWidth, container.clientHeight);
      container.appendChild(renderer.domElement);

      // 5. Add controls
      const controls = new THREE.OrbitControls(camera, renderer.domElement);
      controls.target.set(...rendererTarget);
      controls.update();

      // 6. Add lights
      const ambientLight = new THREE.AmbientLight(0xffffff, 1);
      scene.add(ambientLight);

      // 7. Load PLY files
      const plyLoader = new THREE.PLYLoader();

      // Point cloud
      if (pointcloudPath) {
        plyLoader.load(pointcloudPath, (geometry) => {
          const material = new THREE.PointsMaterial({
            size: 2.0, // point size
            vertexColors: geometry.hasAttribute("color"),
          });
          const points = new THREE.Points(geometry, material);
          scene.add(points);
        });
      }

      // Mesh
      if (meshPath) {
        plyLoader.load(meshPath, (geometry2) => {
          geometry2.computeVertexNormals(); // important for correct lighting
          const material2 = new THREE.MeshPhongMaterial({
            vertexColors: geometry2.hasAttribute("color"),
          });
          const mesh = new THREE.Mesh(geometry2, material2);
          scene.add(mesh);
        });
      }

      // 8. Animation loop
      function animate() {
        requestAnimationFrame(animate);
        controls.update();
        renderer.render(scene, camera);
      }
      animate();

      // 9. Handle resize
      window.addEventListener("resize", () => {
        // We recalculate the size for this container
        const width = container.clientWidth;
        const height = container.clientHeight;
        camera.aspect = width / height;
        camera.updateProjectionMatrix();
        renderer.setSize(width, height);
      });

      // Optionally, return an object that lets you control or cleanup if needed
      return { scene, camera, renderer, controls };
    }
  </script>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Learning to Fly Camera Drones by Watching Internet Videos</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Anonymous Authors
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/anon-submission1/dvgformer"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://1drv.ms/u/c/dfb1b9d32643ecdc/EcHhl1KtZrdHn4wkDJ9Kcg4BtwQCP3f3hKUHS7PArhprnw?e=bctVgD"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>

        <!-- teaser -->
        <!-- <h2 class="subsubtitle has-text-centered"> "To record as is, not to create from scratch." </h2> -->
        <div class="video-container"
          style="margin: 0px; padding: 0px; line-height: 0px; display: grid; grid-template-columns: repeat(4, 1fr); gap: 3px;">
          <!-- real -->
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-nonfpv-blosm/nonfpv_sydney_return10.00_crashNone_602_2024-12-07_04-08-46_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-blosm/fpv_himeji_return10.00_crashNone_7_2024-12-04_13-05-45_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-nonfpv-blosm/nonfpv_melbourne_return10.00_crashNone_206_2024-12-07_03-43-03_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-blosm/fpv_london_return10.00_crashNone_110_2024-12-04_13-13-59_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <!-- synthetic -->
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-infinigen/fpv_cliff_5d162e65_return10.00_crashNone_3901_2024-12-04_17-03-54_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-nonfpv-inifinigen/nonfpv_coast_21f9a55_return10.00_crashNone_1002_2024-12-07_04-34-23_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-infinigen/fpv_mountain_1cf79f9b_return10.00_crashNone_1302_2024-12-04_14-42-49_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls', 'true');" autoplay="" loop="" muted="">
              <source
                src="./static/videos/demo-infinigen/fpv_snowy_mountain_11d35d54_return10.00_crashNone_1601_2024-12-04_14-50-39_online_plus.mp4"
                type="video/mp4">
            </video>
          </div>
        </div>

        <br>
      </div>
    </div>
  </section>
  <br>

  
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-1">
            <video poster="" id="1" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv2/00000_00509_fpv_rome_return10.00_crashNone_2025-04-21_13-44-44_config.txt_2025-10-11_02-18-40_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv2/00509_fpv_rome_return10.00_crashNone_2025-04-21_13-44-44_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-2">
            <video poster="" id="2" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv2/00000_00204_nonfpv_melbourne_return10.00_crashNone_2025-04-09_08-42-31_config.txt_2025-10-11_02-19-57_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv2/00204_nonfpv_melbourne_return10.00_crashNone_2025-04-09_08-42-31_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-3">
            <video poster="" id="3" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv2/00000_02801_fpv_canyon_322e7b67_return10.00_crashNone_2025-04-09_09-12-58_config.txt_2025-10-11_02-20-59_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv2/02801_fpv_canyon_322e7b67_return10.00_crashNone_2025-04-09_09-12-58_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-4">
            <video poster="" id="4" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv2/00000_00601_fpv_sydney_return10.00_crashNone_2025-04-09_08-53-43_config.txt_2025-10-11_02-21-46_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv2/00601_fpv_sydney_return10.00_crashNone_2025-04-09_08-53-43_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-5">
            <video poster="" id="5" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv3/00000_00103_fpv_london_return10.00_crashNone_2025-05-05_22-03-17_config.txt_2025-10-11_02-47-19_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv3/00103_fpv_london_return10.00_crashNone_2025-05-05_22-03-17_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <!-- <div class="item item-6">
            <video poster="" id="6" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv3/00000_00605_fpv_sydney_return10.00_crashNone_2025-05-05_22-24-53_config.txt_2025-10-11_02-47-54_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv3/00605_fpv_sydney_return10.00_crashNone_2025-05-05_22-24-53_config.jpg" style="width: 100%; height: auto;" /> -->
          <!-- </div> -->
          <div class="item item-7">
            <video poster="" id="7" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv3/00000_00205_fpv_melbourne_return10.00_crashNone_2025-05-05_22-09-12_config.txt_2025-10-11_02-49-03_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv3/00205_fpv_melbourne_return10.00_crashNone_2025-05-05_22-09-12_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-8">
            <video poster="" id="8" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv3/00000_01602_nonfpv_snowy_mountain_11d35d54_return10.00_crashNone_2025-05-05_22-38-53_config.txt_2025-10-11_03-05-03_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv3/01602_nonfpv_snowy_mountain_11d35d54_return10.00_crashNone_2025-05-05_22-38-53_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-9">
            <video poster="" id="9" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv3/00000_01802_fpv_canyon_11d0a033_return10.00_crashNone_2025-05-05_22-40-21_config.txt_2025-10-11_03-05-39_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv3/01802_fpv_canyon_11d0a033_return10.00_crashNone_2025-05-05_22-40-21_config.jpg" style="width: 100%; height: auto;" />
          </div>
          <div class="item item-10">
            <video poster="" id="10" autoplay controls muted loop playsinline height="100%">
              <source src="./latex/figs/demo3dv3/00000_03901_fpv_cliff_5d162e65_return10.00_crashNone_2025-05-10_22-28-16_config.txt_2025-10-11_03-15-50_online_plus.mp4"
                      type="video/mp4">
            </video>
            <img src="./latex/figs/demo3dv3/03901_fpv_cliff_5d162e65_return10.00_crashNone_2025-05-10_22-28-16_config.jpg" style="width: 100%; height: auto;" />
          </div>
        </div>
        <span style="font-size: 0.6em; line-height: 0.6;">
          Please be advised that the videos are rendered at a lower quality (64 samples in Blender), potentially affecting the image quality and causing flickers. Since our focus is on <strong>generated camera drone trajectories</strong>, not image quality, we choose this setting for the speed of the rendering.
        </span>
      </div>
      
    </div>
  </section>
  <br>



        
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h3 class="title is-3">Abstract</h3>
            <div class="content has-text-justified">
              <p>
                
Camera drones offer unique perspectives and dynamic motions, yet automating their control for drone videography remains an open question. Unlike navigation or racing, there is no well-accepted reward function for human viewing experiences, making reinforcement learning approaches ill-suited. Therefore, we propose an imitation learning pipeline that learns from Internet videos by mimicking expert operations. In the absence of teleoperation data such as controller inputs and flight logs, we use reconstructed 3D camera poses to estimate camera drone trajectories. Importantly, to ensure data quality, we develop a scalable filtering scheme based on trajectory smoothness. After discarding more than three quarters of processed data, we produce 99k high-quality trajectories, making it the largest camera drone motion dataset. To evaluate this new task, we introduce an interactive evaluation environment with 38 natural scenes and 7 real city scans, and benchmark metrics at both the instance and dataset levels. As a minor contribution, we present a strong baseline named DVGFormer. Despite architectural simplicity, the proposed approach can reproduce complex cinematic behaviors such as obstacleâ€‘aware weaving, scenic reveals, and orbiting shots, verifying the effectiveness of the proposed imitation learning formulation. Data and code are available.
              </p>
            </div>
          </div>
        </div>

        <!-- contribution -->
        <h3 class="title is-3">Contributions</h3>
        <figure class="image" style="margin: 0 auto; max-width: 1000px;">
          <img src="./latex/figs/contribution.jpg" alt="Contribution overview.">
          <!-- <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">.</figcaption> -->
        </figure>
        Our contributions include 
        <ol>
          <li>an imitation learning formulation with a large-scale dataset of real-world camera drone trajectories,</li>
          <li>an interactive evaluation environment with 38 natural scenes and 7 real city scans, plus a set of metrics that assess trajectory quality at both the instance and dataset levels,</li>
          <li>and a strong baseline model named DVGFormer.</li>
        </ol>

        <br>



        <!-- dataset -->
        <h3 class="title is-3">DroneMotion-99k dataset</h3>
        
        <!-- <h5 class="title is-5">Key properties</h5>
        

        <ul>
          <li><strong>Real-world Videos:</strong> Collected from 13,653 YouTube videos, the video clips offer a diverse range of camera drone movements.
          </li>
          <li><strong>Annotation Quality:</strong> From 1k human-labeled trajectories, we derive a threshold that best separates the correct and incorrect reconstructions (see Appendix), and filter out three-quarters of processed data.</li>
          <li><strong>Dataset Scale:</strong> 99,003 high-quality 3D camera trajectories. Duration of 182.3 hours.</li>
        </ul>
        <br> -->

        <h5 class="title is-5">Dataset Creation Pipeline</h5>
        <figure class="image" style="margin: 0 auto; max-width: 1000px;">
          <img src="./latex/figs/data.jpg" alt="Dataset creation pipeline.">
        </figure>
        
        <ul>
          <li><strong>Video Collection:</strong> we downloaded 13,653 YouTube videos, and split them into 449,997 clips of individual scenes.
          </li>
          <li><strong>3D Reconstruction:</strong> we reconstructed 264,596 3D scenes from videos using COLMAP.</li>
          <li><strong>Quality Filtering:</strong> we applied Kalman filter to 3D camera trajectories based on their smoothness, leaving us 99,003 data samples.</li>
        </ul>

        <br>


        
        <h5 class="title is-5">Example Video</h5>
        <div class="video-wrapper">
          <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="">
            <source src="./latex/figs/demo.mp4" type="video/mp4" />
          </video>
          <figure class="image" style="margin: 0 auto; max-width: 1000px;">
            <img src="./latex/figs/demo.jpg" alt="Example of camera drone trajectories in the DroneMotion-99k dataset.">
          </figure>
          <!-- <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">
        Example of camera drone trajectories in the DroneMotion-99k dataset.
          </figcaption> -->
        <br>

        <h5 class="title is-5">Dataset Statistics</h5>
        <figure class="image" style="margin: 0 auto; max-width: 500px;">
          <img src="./latex/figs/data_stats.png" alt="Dataset statistics.">
        </figure>
        
        <ul>
          <li><strong>FPV Drones:</strong> for First-Person-View (FPV) drones, their motion features higher linear and angular speed, and a strong bias towards forward motion.
          </li>
          <li><strong>Non-FPV Drones:</strong> for Non-First-Person-View (Non-FPV) drones, their motion features lower linear and angular speed, usually with stationary or slow movements.</li>
        </ul>

        </div>
        

        <br>
        
        <!-- method -->
        <h3 class="title is-3">DVGFormer Architecture</h3>
        <figure class="image" style="margin: 0 auto; max-width: 1000px;">
          <img src="./latex/figs/model.jpg" alt="DVGFormer architecture.">
        </figure>
        As a minor contribution, we prepare three different DVGFormer models for different prediction settings:
        <ol>
          <li><strong>DVGFormer-A:</strong> predicts the camera trajectory based on the initial image and previous camera poses.</li>
          <li><strong>DVGFormer-B:</strong> predicts the camera trajectory based on all previous images. <strong>This is our default version.</strong></li>
          <li><strong>DVGFormer-C:</strong> predicts the camera trajectory based on previous images, camera poses, and motions.</li>
        </ol>

        <br>

        <!-- contribution -->
        <h3 class="title is-3">Evaluation and Benchmarking</h3>

        
        <h5 class="title is-5">Evaluation Environment</h5>
        <figure class="image" style="margin: 0 auto; max-width: 1000px;">
          <img src="./latex/figs/interactive_eval.png" alt="Interactive evaluation and simulation scenes.">
          <!-- <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">.</figcaption> -->
        </figure>

        <ul>
          <li><strong>Interactive Evaluation Environment:</strong> different from previous works that compare against ground-truth motions from existing videos (<span style="color: red;">predicted motions are not reflected</span>), our evaluation environment is interactive, where the camera drone motion directly influences future images.</li>
          <li><strong>38 Natural Scenes and 7 Real City Scans:</strong> we collected 38 natural scenes from <a href="https://github.com/princeton-vl/infinigen" target="_blank">InfiniGen</a> and 7 real city scans from Google Earth.</li>
        </ul>

        <br>

        <h5 class="title is-5">Quantitative Results</h5>
        <figure class="image" style="margin: 0 auto; max-width: 1000px;">
          <img src="./latex/figs/results_table.png" alt="Quantitative results.">
          <!-- <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">.</figcaption> -->
        </figure>

        <ul>
          <li><strong>CImTr-S:</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  a CLIP-score-like metric that measures the alignment between the predicted camera trajectory and the ground-truth camera trajectory using the proposed <strong>CImTr</strong> features (see Fig. 7 in the manuscript).</li>
          <li><strong>crash:</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  the percentage of predicted camera trajectories that lead to crash.</li>
          <li><strong>perfer.:</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  human preference compared to DVGFormer-C.</li>
          <li><strong>FID<sub>kinetic</sub>:</strong> &nbsp;&nbsp;&nbsp; Frechet Inception Distance using kinetic features (following <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_DanceCamera3D_3D_Camera_Movement_Synthesis_with_Music_and_Dance_CVPR_2024_paper.pdf" target="_blank">Wang et al. 2024</a>).</li>
          <li><strong>FID<sub>CImTr</sub>:</strong> &nbsp;&nbsp;&nbsp;&nbsp;  Frechet Inception Distance using CImTr features.</li>
          <li><strong>div<sub>CImTr</sub>:</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  diversity using CImTr features.</li>
        </ul>

        <br>



        <!-- results -->
        <h3 class="title is-3">Results</h3>


        <h5 class="title is-5">User Conditioning</h5>

        Differences in <strong>drone type</strong> lead to different camera focal length and motion style.
        <div style="
          display: flex;
          gap: 20px;
          justify-content: center;
          align-items: center;
          margin: 20px auto;
          max-width: 1200px;
        ">
          <!-- Video 1 -->
          <div class="video-wrapper" style="flex: 1; max-width: 45%; text-align: center;">
            <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="" style="width: 100%; height: auto;">
              <source src="./latex/figs/demo3dv3/00000_00401_fpv_paris_return10.00_crashNone_2025-05-05_22-15-55_config.txt_2025-10-11_03-33-35_online_plus.mp4" type="video/mp4" />
            </video>
            <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">&lt;style&gt;=FPV</figcaption>
          </div>

          <!-- Video 2 -->
          <div class="video-wrapper" style="flex: 1; max-width: 45%; text-align: center;">
            <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="" style="width: 100%; height: auto;">
              <source src="./latex/figs/demo3dv3/00000_10401_nonfpv_paris_return10.00_crashNone_2025-05-12_20-33-39_config.txt_2025-10-11_03-32-58_online_plus.mp4" type="video/mp4" />
            </video>
            <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">&lt;style&gt;=non-FPV</figcaption>
          </div>
        </div>

        <br>
        
        Differences in <strong>random noise</strong> conditioning lead to different camera drone trajectories.
        <div style="
          display: flex;
          gap: 20px;
          justify-content: center;
          align-items: center;
          margin: 20px auto;
          max-width: 1200px;
        ">
          <!-- Video 1 -->
          <div class="video-wrapper" style="flex: 1; max-width: 45%; text-align: center;">
            <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="" style="width: 100%; height: auto;">
              <source src="./latex/figs/demo3dv3/00000_00007_fpv_himeji_return10.00_crashNone_2025-05-05_22-00-52_config.txt_2025-10-11_03-34-18_online_plus.mp4" type="video/mp4" />
            </video>
            <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">&lt;cond&gt;=randn_1</figcaption>
          </div>

          <!-- Video 2 -->
          <div class="video-wrapper" style="flex: 1; max-width: 45%; text-align: center;">
            <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="" style="width: 100%; height: auto;">
              <source src="./latex/figs/demo3dv3/00000_00007_fpv_himeji_return10.00_crashNone_2025-05-07_04-09-18_config.txt_2025-10-11_03-34-58_online_plus.mp4" type="video/mp4" />
            </video>
            <figcaption class="has-text-centered" style="margin-top: 6px; color: #555;">&lt;cond&gt;=randn_2</figcaption>
          </div>
        </div>

        <br>



        <!-- user extension -->
        <h5 class="title is-5">Camera path extension from user input</h5>
        <div style="
          margin: 0; 
          padding: 0; 
          line-height: 0; 
          display: grid; 
          /* 2 columns: 1 'fraction' for video, 2 'fractions' for 3D */
          grid-template-columns: 1fr 2fr;
          /* 2 rows, one for each video+3D pair */
          grid-template-rows: repeat(2, auto); 
          gap: 3px;
        ">
          <!-- Video 1 -->
          <!-- <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="">
              <source
                src="./static/3d/rome_dvgformer.mp4"
                type="video/mp4" />
            </video>
          </div> -->
          <!-- 3D Viewer 1 -->
          <!-- <div id="viewer1" class="viewer"></div> -->

          <!-- Video 2 -->
          <div class="video-wrapper">
            <video class="video" onclick="setAttribute('controls','true');" autoplay="" loop="" muted="">
              <source src="./static/3d/rome_userforced.mp4" type="video/mp4" />
            </video>
          </div>
          <!-- 3D Viewer 2 -->
          <div id="viewer2" class="viewer"></div>

        </div>
        <script>
          // create3DViewer(
          //   "viewer1",
          //   "./static/3d/rome_pointcloud.ply",      // path to pointcloud
          //   "./static/3d/rome_dvgformer_path.ply",  // path to mesh
          //   [-29.984727, -28.980003, 151.468724],   // camera location
          //   [156.190002, -68.980003, 111.259995]    // camera target
          // );

          create3DViewer(
            "viewer2",
            "./static/3d/rome_pointcloud.ply",
            "./static/3d/rome_userforced_path.ply",
            [-29.984727, -28.980003, 151.468724],
            [184.205633, -139.192592, 120.056117]
          );
        </script>

        <p>
          DVGFormer can smoothly extend <strong>given trajectory</strong> into
          longer sequence. See if you can spot the changes from the user input to the
          generated path by DVGFormer in video! ðŸ¤£
          <span style="color: red;">Scroll to zoom in and drag to change view.</span>

          <!-- Spoiler section -->
        <details>
          <summary style="cursor: pointer; text-decoration: underline;">
            Click to reveal spoiler
          </summary>
          <i><u>Gray camera path and small RGB camera axis are from user input,
              purple path and large RGB camera axis are generated by DVGFormer.</u></i>
        </details>
        </p>

        <br>







        <!-- baseline comparison -->

        <h5 class="title is-5">Comparison with existing methods</h5>
        <p style="margin-bottom: 20px; text-align: center;">
          Compared to existing methods (straight forward, RT-1, DIRECTOR), DVGFormer generates more <strong>diverse and smooth</strong> camera drone trajectories, eliminating the motion jitters and offering improved visual quality.
        </p>

        <!-- Method labels on top -->
        <div style="display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; margin: 20px auto; max-width: 1400px;">
          <div style="text-align: center; font-weight: bold; color: #555; padding: 10px 0;">straight forward</div>
          <div style="text-align: center; font-weight: bold; color: #555; padding: 10px 0;">RT-1</div>
          <div style="text-align: center; font-weight: bold; color: #555; padding: 10px 0;">DIRECTOR</div>
          <div style="text-align: center; font-weight: bold; color: #555; padding: 10px 0;">DVGFormer (Ours)</div>
        </div>

        <script>
          // Load selected videos from txt and generate comparison grids
          document.addEventListener('DOMContentLoaded', function() {
            const container = document.getElementById('comparison-grid-container');
            const methods = ['straight', 'rt1', 'DIRECTOR', 'dvgformer-c'];

            // Fetch and parse txt file
            fetch('./static/videos/userstudy/selected_videos.txt')
              .then(response => response.text())
              .then(txtContent => {
                const videoIds = txtContent.trim().split('\n')
                  .map(id => id.trim())
                  .filter(id => id.length > 0);

                // Generate comparison rows for selected videos
                videoIds.forEach(videoId => {
                  // Add video ID label
                  // const idLabel = document.createElement('div');
                  // idLabel.textContent = `Video ID: ${videoId}`;
                  // idLabel.style.cssText = 'text-align: center; font-weight: bold; color: #333; padding: 15px 0 5px 0; margin: 0 auto; max-width: 1400px;';
                  // container.appendChild(idLabel);
                  
                  const row = document.createElement('div');
                  row.style.cssText = 'display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; margin: 10px auto; max-width: 1400px;';
                  
                  methods.forEach(method => {
                    const videoWrapper = document.createElement('div');
                    videoWrapper.style.cssText = 'text-align: center;';
                    
                    const videoElement = document.createElement('video');
                    videoElement.className = 'video';
                    videoElement.setAttribute('onclick', "setAttribute('controls','true');");
                    videoElement.autoplay = true;
                    videoElement.loop = true;
                    videoElement.muted = true;
                    videoElement.style.cssText = 'width: 100%; height: auto;';
                    
                    const source = document.createElement('source');
                    source.src = `./static/videos/userstudy/${method}/${videoId}.mp4`;
                    source.type = 'video/mp4';
                    
                    videoElement.appendChild(source);
                    videoWrapper.appendChild(videoElement);
                    row.appendChild(videoWrapper);
                  });
                  
                  container.appendChild(row);
                });
              })
              .catch(error => {
                console.error('Error loading video selection:', error);
                // Default to all videos if txt file not found
                const allVideoIds = Array.from({length: 184}, (_, i) => String(i + 1).padStart(3, '0'));
                
                allVideoIds.forEach(videoId => {
                  const row = document.createElement('div');
                  row.style.cssText = 'display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; margin: 10px auto; max-width: 1400px;';
                  
                  methods.forEach(method => {
                    const videoWrapper = document.createElement('div');
                    videoWrapper.style.cssText = 'text-align: center;';
                    
                    const videoElement = document.createElement('video');
                    videoElement.className = 'video';
                    videoElement.setAttribute('onclick', "setAttribute('controls','true');");
                    videoElement.autoplay = true;
                    videoElement.loop = true;
                    videoElement.muted = true;
                    videoElement.style.cssText = 'width: 100%; height: auto;';
                    
                    const source = document.createElement('source');
                    source.src = `./static/videos/userstudy/${method}/${videoId}.mp4`;
                    source.type = 'video/mp4';
                    
                    videoElement.appendChild(source);
                    videoWrapper.appendChild(videoElement);
                    row.appendChild(videoWrapper);
                  });
                  
                  container.appendChild(row);
                });
              });
          });
        </script>

        <div id="comparison-grid-container"></div>



      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://github.com/anon-submission1/dvgformer" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
        <!-- <a class="icon-link" href="https://1drv.ms/u/c/dfb1b9d32643ecdc/EcHhl1KtZrdHn4wkDJ9Kcg4BtwQCP3f3hKUHS7PArhprnw?e=bctVgD" class="external-link" disabled>
          <i class="fab fa-images"></i>
        </a> -->
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Website source code based on the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
              project. If you want to reuse their source code, please credit them.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>